{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2e4872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai_brochure_generator\n",
    "\n",
    "import os\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key or not api_key.startswith(\"sk-proj-\"):\n",
    "    raise ValueError(\"âš ï¸ Invalid or missing OpenAI API key. Check your .env file.\")\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "openai = OpenAI()\n",
    "\n",
    "# Website Scraper Class\n",
    "class WebScraper:\n",
    "    def __init__(self, url: str):\n",
    "        self.url = url\n",
    "        self.html = self._fetch_html()\n",
    "        self.soup = BeautifulSoup(self.html, \"html.parser\")\n",
    "        self.title = self.soup.title.string.strip() if self.soup.title else \"No title found\"\n",
    "        self.text = self._extract_text()\n",
    "        self.links = self._extract_links()\n",
    "\n",
    "    def _fetch_html(self) -> str:\n",
    "        options = Options()\n",
    "        options.add_argument(\"--headless\")\n",
    "        options.add_argument(\"--no-sandbox\")\n",
    "        options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        options.add_argument(\"window-size=1920,1080\")\n",
    "        options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/124.0.0.0 Safari/537.36\")\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "        driver.get(self.url)\n",
    "        html = driver.page_source\n",
    "        driver.quit()\n",
    "        return html\n",
    "\n",
    "    def _extract_text(self) -> str:\n",
    "        if self.soup.body:\n",
    "            for tag in self.soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                tag.decompose()\n",
    "            return self.soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        return \"\"\n",
    "\n",
    "    def _extract_links(self) -> List[str]:\n",
    "        return [a.get(\"href\") for a in self.soup.find_all(\"a\") if a.get(\"href\") and not a.get(\"href\").startswith(\"mailto:\")]\n",
    "\n",
    "    def formatted(self) -> str:\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\"\n",
    "\n",
    "# Prompt for extracting relevant URLs\n",
    "link_filter_prompt = \"\"\"\n",
    "You are provided with a list of links from a company's website. Select those most relevant for a professional brochure.\n",
    "Include pages such as: About Us, Mission, Vision, Innovation, Sustainability, Products, Careers, and Brand.\n",
    "Exclude links like: Contact, Terms, Cookies, Email, Store, Support, Investor Relations, and Social Media.\n",
    "\n",
    "Respond in JSON format:\n",
    "{\n",
    "  \"links\": [\n",
    "    {\"type\": \"about page\", \"url\": \"https://example.com/about\"},\n",
    "    {\"type\": \"careers page\", \"url\": \"https://example.com/jobs\"}\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def generate_link_prompt(scraper: WebScraper) -> str:\n",
    "    return \"\"\"Here is a list of links from the website {}:\\n{}\"\"\".format(scraper.url, \"\\n\".join(scraper.links))\n",
    "\n",
    "def extract_links(url: str) -> List[dict]:\n",
    "    scraper = WebScraper(url)\n",
    "    chat = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": link_filter_prompt},\n",
    "            {\"role\": \"user\", \"content\": generate_link_prompt(scraper)}\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    return json.loads(chat.choices[0].message.content)[\"links\"]\n",
    "\n",
    "def collect_full_content(url: str) -> str:\n",
    "    main_scraper = WebScraper(url)\n",
    "    combined = f\"Landing Page:\\n{main_scraper.formatted()}\"\n",
    "    for item in extract_links(url):\n",
    "        print(f\"Fetching: {item['url']}\")\n",
    "        page = WebScraper(item[\"url\"])\n",
    "        combined += f\"\\n\\n## {item['type'].capitalize()}\\n{page.formatted()}\"\n",
    "    return combined\n",
    "\n",
    "# Brochure prompt setup\n",
    "brochure_prompt = \"\"\"\n",
    "JesteÅ› kreatywnym copywriterem, ktÃ³ry tworzy rozbudowanÄ… broszurÄ™ firmowÄ… na podstawie treÅ›ci pobranej ze strony internetowej.\n",
    "Piszesz po polsku. W kaÅ¼dej sekcji minimum 4â€“6 zdaÅ„. UÅ¼ywasz markdown, emoji, list, pogrubieÅ„ i atrakcyjnego jÄ™zyka.\n",
    "Sekcje: ðŸŽ¯ Dlaczego my, ðŸ› ï¸ Produkty, ðŸ¤ Klienci, ðŸš€ Proces, ðŸŒ WartoÅ›ci, ðŸ“© Kontakt. MoÅ¼esz dodaÄ‡ wÅ‚asne.\n",
    "Broszura ma wyglÄ…daÄ‡ jak atrakcyjny dokument PDF.\n",
    "\"\"\"\n",
    "\n",
    "def make_brochure_prompt(company: str, url: str) -> str:\n",
    "    return f\"Firma: {company}\\n\\nTreÅ›Ä‡ ze strony:\\n\" + collect_full_content(url)[:100_000]\n",
    "\n",
    "def display_brochure(company: str, url: str):\n",
    "    try:\n",
    "        stream = openai.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": brochure_prompt},\n",
    "                {\"role\": \"user\", \"content\": make_brochure_prompt(company, url)}\n",
    "            ],\n",
    "            stream=True\n",
    "        )\n",
    "        response = \"\"\n",
    "        display_handle = display(Markdown(\"\"), display_id=True)\n",
    "        for chunk in stream:\n",
    "            if hasattr(chunk.choices[0].delta, \"content\"):\n",
    "                response += chunk.choices[0].delta.content\n",
    "                update_display(Markdown(response), display_id=display_handle.display_id)\n",
    "    except Exception as error:\n",
    "        print(\"Stream failed. Fallback mode activated.\")\n",
    "        full = openai.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": brochure_prompt},\n",
    "                {\"role\": \"user\", \"content\": make_brochure_prompt(company, url)}\n",
    "            ]\n",
    "        )\n",
    "        display(Markdown(full.choices[0].message.content))\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    display_brochure(\"OpenAI\", \"https://openai.com/\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
